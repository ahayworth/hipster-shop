# opentelemetry-collector can be thought of as a proxy for telemetry events.
# It can receive metrics and traces on many protocols including OTLP and Jaeger,
# do some processing, and forward to many observability tools.
#
# TODO:
#   * add metrics back to this file at some point
#   * add a processor hook to tag stuff as coming from a localdev stack
#
# This setup for local development targets Grafana Tempo
extensions:
  health_check:

receivers:
  otlp:
    protocols:
      grpc:
      http:
  fluentforward:
    endpoint: 0.0.0.0:24224
  redis:
    endpoint: "${REDIS_ADDR}"
    service_name: "cartservice"
    collection_interval: 10s

# TODO: tag all events to make it clear it's localdev
processors:
  batch:
  # We add a derived `service_name` resource attribute to incoming spans in this processor.
  # We do so because we also set the `service_name` Loki label on incoming logs elsewhere.
  # This allows us to more easily correlate logs and traces.
  #
  # We need to use `service_name` instead of the OTel standard `service.name` because Loki doesn't allow for dots in its label names.
  #
  # NB: This is a *resource* processor; and not a *span* processor (and not an *attributes* processor).
  # They all operate on different parts of the signal, and `service.name` is a resource attribute.
  #
  # TODO: correlate logs and traces by trace ID rather than by
  #       service tags (if possible in Grafana)
  resource/span_service_loki:
    attributes:
      - key: service_name
        action: insert
        from_attribute: 'service.name'
  # Here we take the `container_name` added by docker in the fluentd
  # logs, and then extract the service name from it. We set that as
  # the `service_name` tag. That allows us to correlate the logs and
  # spans rather nicely.
  attributes/log_rename_container:
    actions:
      - key: container_name
        action: extract
        pattern: ^/hipster-shop_(?P<service_name>[a-zA-Z]+)

exporters:
  logging:
    # set to debug and your traces will get printed to the console spammily
    logLevel: info
  # local Grafana Tempo
  otlp:
    # forwards to Tempo over gRPC which is configured locally to listen on 55680 (the default for Tempo)
    endpoint: "tempo:55680"
    insecure: true
  prometheus:
    endpoint: "0.0.0.0:9090"
  loki:
    endpoint: "http://loki:3100/loki/api/v1/push"
    labels:
      attributes:
        # The attributes map serves two purposes:
        # 1. The keys function as an allow-list - only logs which have
        #    one of these label names will be forwarded on to Loki.
        # 2. The key/value pair is a transformation - the label whose name
        #    matches the key will have its name transformed as specified.
        #
        # So for example, we could say `service_name: 'unicorns'` - which would
        # allow logs if they have the `service_name` label - and would rewrite
        # that label name to `unicorns` before sending it to Loki (and the label
        # value is untouched). So `service_name: rainbows` is permitted, but is
        # found in Loki as `unicorns: rainbows`.
        #
        # For our purposes, we just want to permit logs which have the `service_name`
        # label. We don't actually care to transform the label name here - it's a
        # functional no-op. The convention in the collector is to set the value to
        # the empty string if you don't actualy want a transformation.
        service_name: ''

  # honeycomb
  # otlp/2:
  #  endpoint: "api.honeycomb.io:443"
  #  headers:
  #    # TODO: figure out how to plumb the key here effectively without hardcoding
  #    "x-honeycomb-team": "-------- your key here ---------"
  #    "x-honeycomb-dataset": "-- your dataset name --"
  # TODO:
  #   * add a Lightstep example
  #   * add Jaeger / Zipkin examples?
  #   * others, as folks send PRs

service:
  extensions:
    - health_check
  pipelines:
    traces:
      receivers:
        - otlp
      processors:
        - resource/span_service_loki
        - batch
      exporters:
        - logging
        - otlp
    metrics:
      receivers:
        - otlp
        - redis
      exporters:
        - logging
        - prometheus
    logs:
      receivers:
        - otlp
        - fluentforward
      processors:
        - attributes/log_rename_container
      exporters:
        - loki
